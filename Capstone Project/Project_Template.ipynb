{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_Template.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "TrrKC5yM-M_-"
      },
      "source": [
        "# ETL Pipeline - Temperature and US Immigration Data\n",
        "### Data Engineering Capstone Project\n",
        "\n",
        "#### Project Summary\n",
        "This project consists of building an ETL pipeline that uses I94 immigration and temperature data to create a database optimized for analyzing immigration events. And the fact table will be used to answer whether the temperature of cities is decisive for the choice of destination by immigrants.\n",
        "\n",
        "The project follows the follow steps:\n",
        "* Step 1: Scope the Project and Gather Data\n",
        "* Step 2: Explore and Assess the Data\n",
        "* Step 3: Define the Data Model\n",
        "* Step 4: Run ETL to Model the Data\n",
        "* Step 5: Complete Project Write Up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yYTdkK8YC6g",
        "outputId": "a45e84e6-2d77-4abe-8c4e-b2970e42cafa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH0_COAZMF0j",
        "outputId": "b3290048-1c6f-4e80-fc33-b739def2cd67"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4 MB 67 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 60.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=5b22cd96ed3cac794c6414a176934eead8c7d4d678bf78ee344adff3b4794a40\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true,
        "id": "mxpjrMbI-NAE"
      },
      "source": [
        "import re\n",
        "from collections import defaultdict\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import pandas as pd\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "import pyspark.sql.functions as F\n",
        "import pyspark.sql.types as t"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "xZB-sLikX4U4",
        "outputId": "6fcf2b13-f1ba-42f0-e2fc-73c6d9d2b5ee"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.\\\n",
        "enableHiveSupport().getOrCreate()\n",
        "spark"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - hive</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://d96ed5df17f3:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f2d64ebfbd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "MZJ6w60u-NAF"
      },
      "source": [
        "### Step 1: Scope the Project and Gather Data\n",
        "\n",
        "#### Scope \n",
        "For this project we created two dimension tables and a fact table. One dimension table consists of I94 immigration data aggregated by destination city, the other dimension table is temperature data aggregated by city. Joining the two tables by city results in the fact table. The last step is the creation of a database to consult immigration events and check whether the temperature has an influence on the choice of destination by immigrants.\n",
        "\n",
        "#### Describe and Gather Data\n",
        "- I94 Immigration Data: provided in SAS7BDAT format, comes from the [US National Tourism and Trade Office website](https://travel.trade.gov/research/reports/i94/historical/2016.html).\n",
        "- Daily Temperature of Major Cities: This dataset came from [Kaggle](https://www.kaggle.com/sudalairajkumar/daily-temperature-of-major-cities) in csv format.\n",
        "\n",
        "*Immigration data - Key Notes:*\n",
        "\n",
        "- i94yr = 4 digit year\n",
        "- i94mon = numeric month\n",
        "- i94cit = 3 digit code of origin city\n",
        "- i94port = 3 character code of destination USA city\n",
        "- arrdate = arrival date in the USA\n",
        "- i94mode = 1 digit travel code\n",
        "- depdate = departure date from the USA\n",
        "- i94visa = reason for immigration\n",
        "\n",
        "*Temperature data - Key Notes:*\n",
        "\n",
        "- Region =  continent name\n",
        "- Country = country name\n",
        "- State = state name\n",
        "- City = city name\n",
        "- Month = number of the month\n",
        "- Day = number of the day\n",
        "- Year = year\n",
        "- AvgTemperature = average temperature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "04MAQeUX-NAG"
      },
      "source": [
        "#### Immigration Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true,
        "id": "9xNxJUy5-NAH"
      },
      "source": [
        "df_immigration = pd.read_sas('/content/drive/MyDrive/Data-Engineering-Nanodegree/Capstone_Project/data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat', 'sas7bdat', encoding='ISO-8859-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "editable": true,
        "id": "w-4izPpX-NAI",
        "outputId": "982784bb-0ba2-42f2-c7ff-08bb58c84ba2"
      },
      "source": [
        "df_immigration.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cicid</th>\n",
              "      <th>i94yr</th>\n",
              "      <th>i94mon</th>\n",
              "      <th>i94cit</th>\n",
              "      <th>i94res</th>\n",
              "      <th>i94port</th>\n",
              "      <th>arrdate</th>\n",
              "      <th>i94mode</th>\n",
              "      <th>i94addr</th>\n",
              "      <th>depdate</th>\n",
              "      <th>i94bir</th>\n",
              "      <th>i94visa</th>\n",
              "      <th>count</th>\n",
              "      <th>dtadfile</th>\n",
              "      <th>visapost</th>\n",
              "      <th>occup</th>\n",
              "      <th>entdepa</th>\n",
              "      <th>entdepd</th>\n",
              "      <th>entdepu</th>\n",
              "      <th>matflag</th>\n",
              "      <th>biryear</th>\n",
              "      <th>dtaddto</th>\n",
              "      <th>gender</th>\n",
              "      <th>insnum</th>\n",
              "      <th>airline</th>\n",
              "      <th>admnum</th>\n",
              "      <th>fltno</th>\n",
              "      <th>visatype</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>692.0</td>\n",
              "      <td>692.0</td>\n",
              "      <td>XXX</td>\n",
              "      <td>20573.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>37.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>T</td>\n",
              "      <td>NaN</td>\n",
              "      <td>U</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1979.0</td>\n",
              "      <td>10282016</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.897628e+09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>B2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>254.0</td>\n",
              "      <td>276.0</td>\n",
              "      <td>ATL</td>\n",
              "      <td>20551.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>AL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20130811</td>\n",
              "      <td>SEO</td>\n",
              "      <td>NaN</td>\n",
              "      <td>G</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1991.0</td>\n",
              "      <td>D/S</td>\n",
              "      <td>M</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.736796e+09</td>\n",
              "      <td>00296</td>\n",
              "      <td>F1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>WAS</td>\n",
              "      <td>20545.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>MI</td>\n",
              "      <td>20691.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20160401</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>T</td>\n",
              "      <td>O</td>\n",
              "      <td>NaN</td>\n",
              "      <td>M</td>\n",
              "      <td>1961.0</td>\n",
              "      <td>09302016</td>\n",
              "      <td>M</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OS</td>\n",
              "      <td>6.666432e+08</td>\n",
              "      <td>93</td>\n",
              "      <td>B2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>NYC</td>\n",
              "      <td>20545.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>MA</td>\n",
              "      <td>20567.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20160401</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>NaN</td>\n",
              "      <td>M</td>\n",
              "      <td>1988.0</td>\n",
              "      <td>09302016</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AA</td>\n",
              "      <td>9.246846e+10</td>\n",
              "      <td>00199</td>\n",
              "      <td>B2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>NYC</td>\n",
              "      <td>20545.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>MA</td>\n",
              "      <td>20567.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20160401</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>NaN</td>\n",
              "      <td>M</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>09302016</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AA</td>\n",
              "      <td>9.246846e+10</td>\n",
              "      <td>00199</td>\n",
              "      <td>B2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cicid   i94yr  i94mon  i94cit  ...  airline        admnum  fltno  visatype\n",
              "0    6.0  2016.0     4.0   692.0  ...      NaN  1.897628e+09    NaN        B2\n",
              "1    7.0  2016.0     4.0   254.0  ...      NaN  3.736796e+09  00296        F1\n",
              "2   15.0  2016.0     4.0   101.0  ...       OS  6.666432e+08     93        B2\n",
              "3   16.0  2016.0     4.0   101.0  ...       AA  9.246846e+10  00199        B2\n",
              "4   17.0  2016.0     4.0   101.0  ...       AA  9.246846e+10  00199        B2\n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "cZ6GSn3X-NAI"
      },
      "source": [
        "#### Temperature Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true,
        "id": "7LtmY_Tw-NAJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdf4c5ea-d625-4f4b-9f5b-0c096bf9f959"
      },
      "source": [
        "df_temperature = pd.read_csv('/content/drive/MyDrive/Datasets/city_temperature.csv')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "editable": true,
        "id": "-4iB9-Dd-NAK",
        "outputId": "6234ffe1-9350-411b-9b44-b3e42707ed4c"
      },
      "source": [
        "df_temperature.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Region</th>\n",
              "      <th>Country</th>\n",
              "      <th>State</th>\n",
              "      <th>City</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Year</th>\n",
              "      <th>AvgTemperature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Africa</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Algiers</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1995</td>\n",
              "      <td>64.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Africa</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Algiers</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1995</td>\n",
              "      <td>49.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Africa</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Algiers</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1995</td>\n",
              "      <td>48.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Africa</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Algiers</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1995</td>\n",
              "      <td>46.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Africa</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Algiers</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1995</td>\n",
              "      <td>47.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Region  Country State     City  Month  Day  Year  AvgTemperature\n",
              "0  Africa  Algeria   NaN  Algiers      1    1  1995            64.2\n",
              "1  Africa  Algeria   NaN  Algiers      1    2  1995            49.4\n",
              "2  Africa  Algeria   NaN  Algiers      1    3  1995            48.8\n",
              "3  Africa  Algeria   NaN  Algiers      1    4  1995            46.4\n",
              "4  Africa  Algeria   NaN  Algiers      1    5  1995            47.9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "VaslKnMD-NAN"
      },
      "source": [
        "### Step 2: Explore and Assess the Data\n",
        "#### Explore the Data \n",
        "*Immigration data* - filter data points that have valid i94port, rename columns with understandable names, extract number of the day from arrival date and convert dates to date format.\n",
        "\n",
        "*Temperature Data* - drop data points where AvgTemperature is null, filter only US cities, add i94port in each entry and drop rows where i94port is null."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true,
        "id": "UtFH3oOyX4VC"
      },
      "source": [
        "with open('I94_SAS_Labels_Descriptions.SAS') as f:\n",
        "    lines=f.readlines()\n",
        "    df_i94port = pd.DataFrame(lines[303:962])\n",
        "\n",
        "i94ports = {}\n",
        "for index, row in df_i94port.iterrows():\n",
        "    i94ports[df_i94port[0][index].split(\"'\")[1]] = [df_i94port[0][index].split(\"'\")[3].split(',')[0]]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true,
        "id": "yFH9hs_o-NAO"
      },
      "source": [
        "def cleaner_immigration_data(spark, path, i94port):\n",
        "    '''    \n",
        "    Input:\n",
        "        spark = Spark Session\n",
        "        path = I94 immigration file path\n",
        "        i94port = list of i94 ports\n",
        "    \n",
        "    Output:\n",
        "        spark_df = Spark DataFrame\n",
        "    '''    \n",
        "    spark_df = spark.read.parquet(path)\n",
        "    spark_df = spark_df.filter(spark_df.i94port.isin(list(i94port.keys())))\n",
        "\n",
        "    spark_df = spark_df.withColumn('year', col('i94yr').cast('integer')).drop('i94yr') \\\n",
        "                       .withColumn('month', col('i94mon').cast('integer')).drop('i94mon') \\\n",
        "                       .withColumn('visa', col('i94visa').cast('integer')).drop('i94visa') \\\n",
        "                       .withColumn('mode', col('i94mode').cast('integer')).drop('i94mode') \\\n",
        "                       .withColumn('origin_country', col('i94res').cast('integer')).drop('i94res') \\\n",
        "                       .withColumn('origin_city', col('i94cit').cast('integer')).drop('i94cit') \\\n",
        "                       .withColumn('age', col('i94bir').cast('integer')).drop('i94bir') \\\n",
        "                       .withColumn('arrival_date', col('arrdate').cast('integer')).drop('arrdate') \\\n",
        "                       .withColumn('departure_date', col('depdate').cast('integer')).drop('depdate')\n",
        "    \n",
        "    spark_df = spark_df.filter(spark_df.departure_date.isNotNull())\n",
        "\n",
        "    def extract_day(days):\n",
        "        date_format = datetime.strptime('1960-01-01', \"%Y-%m-%d\")+timedelta(days)\n",
        "        return date_format.day\n",
        "\n",
        "    day_udf = udf(extract_day, t.StringType())\n",
        "\n",
        "    spark_df = spark_df.withColumn('arrival_day', day_udf('arrival_date')) \\\n",
        "                       .withColumn('arrival_day', col('arrival_day').cast('integer'))\n",
        "\n",
        "    def convert_date(days):\n",
        "        date_format = datetime.strptime('1960-01-01', \"%Y-%m-%d\")+timedelta(days)\n",
        "        return date_format.strftime('%Y-%m-%d')\n",
        "\n",
        "    date_udf = udf(convert_date, t.StringType())\n",
        "\n",
        "    spark_df = spark_df.withColumn('arrival_date', date_udf('arrival_date')) \\\n",
        "                        .withColumn('departure_date', date_udf('departure_date'))\n",
        "    \n",
        "    return spark_df.select(col('i94port'), col('year'),\n",
        "                           col('month'), col('arrival_day'), col('origin_country'),\n",
        "                           col('origin_city'), col('arrival_date'),\n",
        "                           col('departure_date'), col('visa'), col('mode'),\n",
        "                           col('age'), col('gender'))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "editable": true,
        "id": "DAj5gsjs-NAP",
        "outputId": "183b59e4-5d67-4fe3-bc1d-22d431fd7536"
      },
      "source": [
        "df_imm = cleaner_immigration_data(spark, '/content/drive/MyDrive/Data-Engineering-Nanodegree/Capstone_Project/sas_data', i94ports)\n",
        "df_imm.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----+-----+-----------+--------------+-----------+------------+--------------+----+----+---+------+\n",
            "|i94port|year|month|arrival_day|origin_country|origin_city|arrival_date|departure_date|visa|mode|age|gender|\n",
            "+-------+----+-----+-----------+--------------+-----------+------------+--------------+----+----+---+------+\n",
            "|    LOS|2016|    4|         30|           438|        245|  2016-04-30|    2016-05-08|   1|   1| 40|     F|\n",
            "|    LOS|2016|    4|         30|           438|        245|  2016-04-30|    2016-05-17|   1|   1| 32|     F|\n",
            "|    LOS|2016|    4|         30|           438|        245|  2016-04-30|    2016-05-08|   1|   1| 29|     M|\n",
            "|    LOS|2016|    4|         30|           438|        245|  2016-04-30|    2016-05-14|   1|   1| 29|     F|\n",
            "|    LOS|2016|    4|         30|           438|        245|  2016-04-30|    2016-05-14|   1|   1| 28|     M|\n",
            "|    HHW|2016|    4|         30|           464|        245|  2016-04-30|    2016-05-05|   2|   1| 57|     M|\n",
            "|    HHW|2016|    4|         30|           464|        245|  2016-04-30|    2016-05-12|   2|   1| 66|     F|\n",
            "|    HHW|2016|    4|         30|           464|        245|  2016-04-30|    2016-05-12|   2|   1| 41|     F|\n",
            "|    HOU|2016|    4|         30|           464|        245|  2016-04-30|    2016-05-07|   2|   1| 27|     M|\n",
            "|    LOS|2016|    4|         30|           464|        245|  2016-04-30|    2016-05-07|   2|   1| 26|     F|\n",
            "|    NEW|2016|    4|         30|           504|        245|  2016-04-30|    2016-05-02|   2|   1| 44|     M|\n",
            "|    LOS|2016|    4|         30|           504|        245|  2016-04-30|    2016-05-01|   2|   1| 39|     M|\n",
            "|    WAS|2016|    4|         30|           504|        245|  2016-04-30|    2016-05-22|   2|   1| 38|     M|\n",
            "|    LOS|2016|    4|         30|           504|        245|  2016-04-30|    2016-05-03|   2|   1| 56|     F|\n",
            "|    LOS|2016|    4|         30|           504|        245|  2016-04-30|    2016-05-03|   2|   1| 38|     M|\n",
            "|    MIA|2016|    4|         30|           504|        245|  2016-04-30|    2016-05-07|   2|   1| 53|     F|\n",
            "|    HOU|2016|    4|         30|           582|        245|  2016-04-30|    2016-05-09|   1|   1| 43|     M|\n",
            "|    HOU|2016|    4|         30|           582|        245|  2016-04-30|    2016-05-09|   1|   1| 30|     F|\n",
            "|    LOS|2016|    4|         30|           582|        245|  2016-04-30|    2016-05-01|   2|   1| 34|     M|\n",
            "|    DAL|2016|    4|         30|           690|        245|  2016-04-30|    2016-05-04|   2|   1| 30|     F|\n",
            "+-------+----+-----+-----------+--------------+-----------+------------+--------------+----+----+---+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VERnDyG4V1Vk"
      },
      "source": [
        "@udf()\n",
        "def get_i94_port(city):\n",
        "    '''\n",
        "    Input: City name\n",
        "    Output: City i94port code\n",
        "    \n",
        "    '''\n",
        "    for key in i94ports:\n",
        "        if city.lower() == i94ports[key][0].lower():\n",
        "            return key\n",
        "\n",
        "\n",
        "def cleaner_temperature_data(spark, path):\n",
        "    '''    \n",
        "    Input:\n",
        "        spark = Spark Session\n",
        "        path = temperature file path\n",
        "    \n",
        "    Output:\n",
        "        spark_df = Spark DataFrame\n",
        "    '''    \n",
        "    spark_df = spark.read.format('csv').option('header', 'true').load(path)\n",
        "    spark_df = spark_df.filter(spark_df.AvgTemperature.isNotNull())\n",
        "    spark_df = spark_df.filter(spark_df.Country == 'US')\n",
        "    spark_df = spark_df.withColumn('i94port', get_i94_port(spark_df.City)) \\\n",
        "                       .withColumnRenamed('AvgTemperature', 'temperature') \\\n",
        "                       .withColumnRenamed('City', 'city') \\\n",
        "                       .withColumnRenamed('Country', 'country') \\\n",
        "                       .withColumnRenamed('Year', 'year') \\\n",
        "                       .withColumnRenamed('Month', 'month') \\\n",
        "                       .withColumnRenamed('Day', 'day')\n",
        "    \n",
        "    spark_df = spark_df.filter(spark_df.i94port.isNotNull())\n",
        "\n",
        "    return spark_df.select(col('i94port'), col('temperature'), col('city'),\n",
        "                           col('country'), col('year'),\n",
        "                           col('month'), col('day'))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ssl5Nue1WqJ2",
        "outputId": "9cd24264-a4e7-4e01-f785-d56080d38c8c"
      },
      "source": [
        "df_temp = cleaner_temperature_data(spark, '/content/drive/MyDrive/Datasets/city_temperature.csv')\n",
        "df_temp.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----------+----------+-------+----+-----+---+\n",
            "|i94port|temperature|      city|country|year|month|day|\n",
            "+-------+-----------+----------+-------+----+-----+---+\n",
            "|    BHX|       50.7|Birmingham|     US|1995|    1|  1|\n",
            "|    BHX|       37.2|Birmingham|     US|1995|    1|  2|\n",
            "|    BHX|       33.2|Birmingham|     US|1995|    1|  3|\n",
            "|    BHX|       33.3|Birmingham|     US|1995|    1|  4|\n",
            "|    BHX|       26.4|Birmingham|     US|1995|    1|  5|\n",
            "|    BHX|       41.5|Birmingham|     US|1995|    1|  6|\n",
            "|    BHX|       45.0|Birmingham|     US|1995|    1|  7|\n",
            "|    BHX|       36.2|Birmingham|     US|1995|    1|  8|\n",
            "|    BHX|       46.9|Birmingham|     US|1995|    1|  9|\n",
            "|    BHX|       46.4|Birmingham|     US|1995|    1| 10|\n",
            "|    BHX|       58.8|Birmingham|     US|1995|    1| 11|\n",
            "|    BHX|       64.4|Birmingham|     US|1995|    1| 12|\n",
            "|    BHX|       64.4|Birmingham|     US|1995|    1| 13|\n",
            "|    BHX|       59.7|Birmingham|     US|1995|    1| 14|\n",
            "|    BHX|       48.1|Birmingham|     US|1995|    1| 15|\n",
            "|    BHX|       43.7|Birmingham|     US|1995|    1| 16|\n",
            "|    BHX|       42.5|Birmingham|     US|1995|    1| 17|\n",
            "|    BHX|       49.7|Birmingham|     US|1995|    1| 18|\n",
            "|    BHX|       53.0|Birmingham|     US|1995|    1| 19|\n",
            "|    BHX|       43.5|Birmingham|     US|1995|    1| 20|\n",
            "+-------+-----------+----------+-------+----+-----+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "32wUBz8m-NAR"
      },
      "source": [
        "### Step 3: Define the Data Model\n",
        "#### 3.1 Conceptual Data Model\n",
        "\n",
        "The purpose of this database is to aggregate immigration and temperature events using star schema, where the data is modeled in two dimensional tables linked to a fact table. Dimensional tables contain the characteristics of an event. The fact table stores the occurred facts and keys (i94port) for the corresponding characteristics in the dimensional tables.\n",
        "\n",
        "Fact Table - I94 immigration data joined with the city temperature data on i94port:\n",
        "- i94port = 3 character code of destination USA city\n",
        "- year = 4 digit year (i94yr)\n",
        "- month = numeric month (i94mon)\n",
        "- arrival_day = arrival day in the USA\n",
        "- departure_date = departure date from the USA (depdate)\n",
        "- visa = visa type (reason for immigration)\n",
        "- mode = transport mode\n",
        "- city = city name\n",
        "- temperature = average temperature of destination city\n",
        "\n",
        "Dimension Table - I94 immigration data Events:\n",
        "- i94port = 3 character code of destination USA city\n",
        "- year = 4 digit year (i94yr)\n",
        "- month = numeric month (i94mon)\n",
        "- arrival_day = arrival day in the USA\n",
        "- origin_country = 3 digit code of origin country (i94res)\n",
        "- origin_city = 3 digit code of origin city (i94cit)\n",
        "- arrival_date = arrival date in the USA (arrdate)\n",
        "- departure_date = departure date from the USA (depdate)\n",
        "- mode = transport mode (i94mode)\n",
        "- visa = reason for immigration (i94visa)\n",
        "- age = immigrant age (i94bir)\n",
        "- gender = immigrant gender (i94visa)\n",
        "\n",
        "Dimension Table - Temperature data:\n",
        "- i94port = 3 character code of destination city\n",
        "- temperature = average temperature\n",
        "- city = city name\n",
        "- country = country name\n",
        "- year = year\n",
        "- month = month\n",
        "- day = day\n",
        "\n",
        "#### 3.2 Mapping Out Data Pipelines\n",
        "Pipeline Steps:\n",
        "\n",
        "- Clean immigration data to create Spark dataframe **df_imm**.\n",
        "- Clean temperature data to create Spark dataframe **df_temp**.\n",
        "- Create immigration dimension table by selecting columns from **df_imm** and write to parquet file partitioned by i94port.\n",
        "- Create temperature dimension table by selecting columns from **df_temp** and write to parquet file partitioned by i94port.\n",
        "- Create fact table by joining immigration and temperature dimension tables on i94port and write to parquet file partitioned by i94port where the arrival date (day) equals the temperature date."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "n5D1wouU-NAR"
      },
      "source": [
        "### Step 4: Run Pipelines to Model the Data \n",
        "#### 4.1 Create the data model\n",
        "Build the data pipelines to create the data model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true,
        "id": "SDQ0uQRrX4VH"
      },
      "source": [
        "class DataPipeline:\n",
        "    '''\n",
        "    Pipeline to extract data from Spark dataframe and write to the database\n",
        "    Inputs: \n",
        "        spark = Spark Session\n",
        "        spark_df = spark dataframe from which the data is extracted\n",
        "        select_columns = name of columns that should be selected from spark_df\n",
        "        write_path = path where the data will be written\n",
        "        fact_table = fact table for quality check\n",
        "    '''   \n",
        "    def __init__(self, spark):\n",
        "        self.spark = spark\n",
        "    \n",
        "    def select(self, spark_df, select_columns):\n",
        "        self.spark_df = spark_df\n",
        "        self.columns = select_columns\n",
        "\n",
        "        self.table = self.spark_df.select(self.columns)\n",
        "        \n",
        "        return self.table\n",
        "        \n",
        "    def write(self, write_path):\n",
        "        self.write_path = write_path\n",
        "        self.table.write.mode('append').partitionBy('i94port').parquet(f'{self.write_path}.parquet')\n",
        "\n",
        "    def quality_check(self, fact_table):\n",
        "        if self.spark_df.count() == 0:\n",
        "            print('Warning! The dataframe has zero records.')\n",
        "        else:\n",
        "            print('The dataframe has records.')\n",
        "        \n",
        "        check_table = spark.read.parquet(f'{self.write_path}.parquet')\n",
        "\n",
        "        check_integrity = fact_table.select(col('i94port')).distinct() \\\n",
        "                                       .join(check_table, fact_table['i94port'] == check_table['i94port'], 'left_anti') \\\n",
        "                                       .count() == 0\n",
        "        if check_integrity:\n",
        "            print('The model has no integrity restrictions.')\n",
        "        else:\n",
        "            print('Warning! The model has integrity restrictions.')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "4_51f-ll-NAR"
      },
      "source": [
        "##### Step 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true,
        "id": "E7W4GYmE-NAS"
      },
      "source": [
        "immigration_columns = ['i94port', 'year', 'month', 'arrival_day', 'origin_country',\n",
        "                       'origin_city', 'arrival_date', 'departure_date',\n",
        "                       'visa', 'mode', 'age', 'gender']\n",
        "immigration_table = DataPipeline(spark)\n",
        "immigration_table.select(df_imm, immigration_columns)\n",
        "immigration_table.write('immigration')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "T0AetyXV-NAT"
      },
      "source": [
        "##### Step 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true,
        "id": "wXz2J5JN-NAT"
      },
      "source": [
        "temperature_columns = ['i94port', 'temperature', 'city', 'country', 'year', 'month', 'day']\n",
        "temperature_table = DataPipeline(spark)\n",
        "temperature_table.select(df_temp, temperature_columns)\n",
        "temperature_table.write('temperature')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "5rIZyPf1-NAU"
      },
      "source": [
        "##### Step 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SsMvMz2OhLJ"
      },
      "source": [
        "df_imm.createOrReplaceTempView('imm_view')\n",
        "df_temp.createOrReplaceTempView('temp_view')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true,
        "id": "rpjibP_M-NAU"
      },
      "source": [
        "fact = spark.sql('''\n",
        "SELECT imm_view.i94port as i94port,\n",
        "       imm_view.year as year,\n",
        "       imm_view.month as month,\n",
        "       imm_view.arrival_day as arrival_day,\n",
        "       imm_view.departure_date as departure_date,\n",
        "       imm_view.visa as visa,\n",
        "       imm_view.mode as mode,\n",
        "       temp_view.city as city,\n",
        "       temp_view.temperature as temperature\n",
        "FROM imm_view\n",
        "JOIN temp_view ON (imm_view.i94port = temp_view.i94port)\n",
        "WHERE imm_view.year = temp_view.year AND imm_view.month = temp_view.month AND imm_view.arrival_day = temp_view.day\n",
        "''')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true,
        "id": "uk6Oxyxs-NAV"
      },
      "source": [
        "fact.write.mode('append').partitionBy('i94port').parquet('fact.parquet')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "YV1sBxcg-NAV"
      },
      "source": [
        "#### 4.2 Data Quality Checks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "ufwwscssX4VK"
      },
      "source": [
        "Run Quality Checks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true,
        "id": "S_D3VyzgX4VM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bcefe68-9416-4a4e-a70a-6f5d97dc3948"
      },
      "source": [
        "immigration_table.quality_check(fact)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The dataframe has records.\n",
            "The model has no integrity restrictions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true,
        "id": "PWk14rWM-NAW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fe39b70-a045-4392-993e-5881198f7ba0"
      },
      "source": [
        "temperature_table.quality_check(fact)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The dataframe has records.\n",
            "The model has no integrity restrictions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "SCTd_0PC-NAW"
      },
      "source": [
        "#### 4.3 Data dictionary \n",
        "* *Fact Table - I94 immigration data joined with the city temperature data (i94port):*\n",
        "\n",
        "| **field**          | **type** | **description**                         |\n",
        "|--------------------|----------|-----------------------------------------|\n",
        "| i94port            | string   | i94 code (city code)                    |\n",
        "| year               | int      | year                                    |\n",
        "| month              | int      | month                                   |\n",
        "| arrival_day       | date     |  arrival day in the USA                 |\n",
        "| departure_date     | date     | departure date from the USA             |\n",
        "| visa            | int      | visa code (1=Business, 2=Pleasure, 3=Strudent)      |\n",
        "| mode            | int      | mode code (1=Air, 2=Sea, 3=Land, 9=Uninformed)      |\n",
        "| city               | string   | destination city                               |\n",
        "| temperature | numeric  | average temperature of destination city |\n",
        "\n",
        "\n",
        "* *Dimension Table 1 - I94 immigration data Events:*\n",
        "\n",
        "| **field** | **type** | **description**                    |\n",
        "|-----------|----------|------------------------------------|\n",
        "| i94port   | string   | i94 code (city code)               |\n",
        "| year     | int      | year                               |\n",
        "| month    | int      | month                              |\n",
        "| origin_country    | int      | country code                       |\n",
        "| origin_city    | int      | city code                       |\n",
        "| arrdate   | date     | arrival date in the USA            |\n",
        "| depdate   | date     | departure date from the USA        |\n",
        "| mode            | int      | mode code (1=Air, 2=Sea, 3=Land, 9=Uninformed)      |\n",
        "| visa            | int      | visa code (1=Business, 2=Pleasure, 3=Strudent)      |\n",
        "| age   | int     | immigrant age        |\n",
        "| gender   | string     | immigrant gender        |\n",
        "\n",
        "* *Dimension Table 2 - Temperature data:*\n",
        "\n",
        "| **field**           | **type** | **description**                         |\n",
        "|---------------------|----------|-----------------------------------------|\n",
        "| i94port             | string   | i94 code (city code)                    |\n",
        "| temperature  | numeric  | average temperature of destination city |\n",
        "| city                | string   | destination city                               |\n",
        "| country             | string   | destination country                           |\n",
        "| year            | int   | year                    |\n",
        "| month           | int   | number of the month                   |\n",
        "| day           | int   | number of the day                   |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "XMGbKkKA-NAX"
      },
      "source": [
        "#### Step 5: Complete Project Write Up\n",
        "**Choice of tools**\n",
        "\n",
        "Apache Spark was used in the project due to its ability to work with large amounts of data and with different file formats, in addition to having spark.sql library has many tools for transforming data, such as performing joins and creating tables.\n",
        "\n",
        "**Data updates**\n",
        "\n",
        "Due to the nature of the data being monthly, the update is ideally carried out monthly.\n",
        "\n",
        "**Adapting the project to different scenarios**\n",
        "\n",
        "*1. Increase in data volume by 100x*\n",
        "\n",
        "In this scenario Spark remains the tool to be used. To run this pipeline for a 100x dataset a real spark cluster must be used and distribute the calculation to several nodes.\n",
        "\n",
        "*2. The data populates a dashboard that must be updated on a daily basis by 7am every day*\n",
        "\n",
        "For this case the ideal tool is Apache Airflow, with it you can reliably hijack and run ETL pipelines and report any problems along the way.\n",
        "\n",
        "*3. The database needs to be accessed by 100+ people*\n",
        "\n",
        "One option would be to put the data into S3 and create a pipeline with Airflow or AWS Step Functions to move the data from S3 to a scalable DataWarehouse on Amazon Redshift. If the database only receives queries and does not receive inserts or updates, the data can be periodically copied to a NoSQL database like Cassandra."
      ]
    }
  ]
}